import pandas as pd
import numpy as np
from scipy import stats
import statsmodels.api as sm
from statsmodels.stats import power, proportion
import matplotlib.pyplot as plt
import seaborn as sns
from sqlalchemy import create_engine
import warnings

warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)


# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
def connect_to_db():
    """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ SQL Server"""
    connection_string = (
        'mssql+pyodbc://@localhost/marketing_analysis?'
        'driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes'
    )
    return create_engine(connection_string)


def load_ab_test_data(engine):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö A/B —Ç–µ—Å—Ç–∞"""

    query = """
    WITH test_data AS (
        SELECT 
            au.group_name,
            au.test_id,
            au.device_type,
            au.browser,
            au.traffic_source,
            CASE WHEN EXISTS (
                SELECT 1 FROM ab_test_events ae 
                WHERE ae.test_id = au.test_id AND ae.event_type = 'purchase'
            ) THEN 1 ELSE 0 END as converted,
            (SELECT COUNT(*) FROM ab_test_events ae2 
             WHERE ae2.test_id = au.test_id) as total_events,
            (SELECT COUNT(*) FROM ab_test_events ae3 
             WHERE ae3.test_id = au.test_id AND ae3.event_type = 'add_to_cart') as cart_events,
            (SELECT AVG(session_duration) FROM ab_test_events ae4 
             WHERE ae4.test_id = au.test_id) as avg_session_duration,
            (SELECT AVG(scroll_depth) FROM ab_test_events ae5 
             WHERE ae5.test_id = au.test_id) as avg_scroll_depth,
            ao.order_amount,
            ao.items_count,
            ao.conversion_time
        FROM ab_test_users au
        LEFT JOIN ab_test_orders ao ON au.test_id = ao.test_id
    )
    SELECT * FROM test_data
    """

    return pd.read_sql(query, engine)


def calculate_basic_metrics(df):
    """–†–∞—Å—á–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""

    print("=" * 80)
    print("–û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò A/B –¢–ï–°–¢–ê")
    print("=" * 80)

    # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≥—Ä—É–ø–ø–∞–º
    control = df[df['group_name'] == 'control']
    variant = df[df['group_name'] == 'variant']

    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    metrics = pd.DataFrame({
        '–ú–µ—Ç—Ä–∏–∫–∞': [
            '–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏',
            '–ö–æ–Ω–≤–µ—Ä—Å–∏—è (%)',
            '–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π',
            '–î–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –∫–æ—Ä–∑–∏–Ω—É',
            '–°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ—Å—Å–∏–∏ (—Å–µ–∫)',
            '–ì–ª—É–±–∏–Ω–∞ –ø—Ä–æ–∫—Ä—É—Ç–∫–∏ (%)',
            '–°—Ä–µ–¥–Ω–∏–π —á–µ–∫ ($)',
            '–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –¥–æ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏ (—Å–µ–∫)'
        ],
        'Control': [
            len(control),
            control['converted'].mean() * 100,
            control['total_events'].mean(),
            control['cart_events'].mean(),
            control['avg_session_duration'].mean(),
            control['avg_scroll_depth'].mean(),
            control['order_amount'].mean(),
            control['conversion_time'].mean()
        ],
        'Variant': [
            len(variant),
            variant['converted'].mean() * 100,
            variant['total_events'].mean(),
            variant['cart_events'].mean(),
            variant['avg_session_duration'].mean(),
            variant['avg_scroll_depth'].mean(),
            variant['order_amount'].mean(),
            variant['conversion_time'].mean()
        ]
    })

    # –†–∞—Å—á–µ—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
    metrics['–†–∞–∑–Ω–∏—Ü–∞'] = metrics['Variant'] - metrics['Control']
    metrics['–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ (%)'] = (metrics['Variant'] / metrics['Control'] - 1) * 100

    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–µ–ª
    for col in ['Control', 'Variant', '–†–∞–∑–Ω–∏—Ü–∞']:
        metrics[col] = metrics[col].apply(lambda x: f"{x:.2f}" if pd.notnull(x) else "N/A")

    metrics['–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ (%)'] = metrics['–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ (%)'].apply(
        lambda x: f"{x:.1f}%" if pd.notnull(x) else "N/A"
    )

    print(metrics.to_string(index=False))

    return control, variant


def perform_statistical_tests(control, variant):
    """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤"""

    print("\n" + "=" * 80)
    print("–°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ï –¢–ï–°–¢–´")
    print("=" * 80)

    # 1. Z-—Ç–µ—Å—Ç –¥–ª—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–π (–∫–æ–Ω–≤–µ—Ä—Å–∏—è)
    control_conversions = control['converted'].sum()
    control_size = len(control)
    variant_conversions = variant['converted'].sum()
    variant_size = len(variant)

    # –í—ã—á–∏—Å–ª—è–µ–º Z-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—Ä—É—á–Ω—É—é
    p_control = control_conversions / control_size
    p_variant = variant_conversions / variant_size
    p_pooled = (control_conversions + variant_conversions) / (control_size + variant_size)

    z_score = (p_variant - p_control) / np.sqrt(
        p_pooled * (1 - p_pooled) * (1 / control_size + 1 / variant_size)
    )

    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))

    print(f"1. Z-—Ç–µ—Å—Ç –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Å–∏–∏:")
    print(f"   Z-score: {z_score:.4f}")
    print(f"   P-value: {p_value:.6f}")
    print(f"   –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ: {'–î–ê' if p_value < 0.05 else '–ù–ï–¢'}")

    # 2. –†–∞—Å—á–µ—Ç –º–æ—â–Ω–æ—Å—Ç–∏ —Ç–µ—Å—Ç–∞
    effect_size = proportion.proportion_effectsize(p_control, p_variant)
    power_analysis = power.NormalIndPower()
    achieved_power = power_analysis.solve_power(
        effect_size=effect_size,
        nobs1=variant_size,
        alpha=0.05,
        ratio=control_size / variant_size
    )

    print(f"\n2. –ú–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞ (Power): {achieved_power:.3f}")
    print(f"   –≠—Ñ—Ñ–µ–∫—Ç –ö–æ—ç–Ω–∞ (h): {effect_size:.3f}")

    # 3. –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –¥–ª—è —Ä–∞–∑–Ω–∏—Ü—ã
    diff = p_variant - p_control
    se = np.sqrt(p_control * (1 - p_control) / control_size + p_variant * (1 - p_variant) / variant_size)
    ci_lower = diff - 1.96 * se
    ci_upper = diff + 1.96 * se

    print(f"\n3. –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª —Ä–∞–∑–Ω–∏—Ü—ã –∫–æ–Ω–≤–µ—Ä—Å–∏–π (95%):")
    print(f"   –†–∞–∑–Ω–∏—Ü–∞: {diff:.4f} ({diff * 100:.2f}%)")
    print(f"   –î–ò: [{ci_lower:.4f}, {ci_upper:.4f}]")
    print(f"   –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ: {(p_variant / p_control - 1) * 100:.1f}%")

    # 4. T-—Ç–µ—Å—Ç –¥–ª—è –º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    print(f"\n4. T-—Ç–µ—Å—Ç—ã –¥–ª—è –¥—Ä—É–≥–∏—Ö –º–µ—Ç—Ä–∏–∫:")

    metrics_to_test = [
        ('total_events', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π'),
        ('cart_events', '–î–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –∫–æ—Ä–∑–∏–Ω—É'),
        ('avg_session_duration', '–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ—Å—Å–∏–∏'),
        ('order_amount', '–°—Ä–µ–¥–Ω–∏–π —á–µ–∫')
    ]

    results = []
    for metric, name in metrics_to_test:
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        c_data = control[metric].dropna()
        v_data = variant[metric].dropna()

        if len(c_data) > 1 and len(v_data) > 1:
            t_stat, p_val = stats.ttest_ind(c_data, v_data, equal_var=False)
            results.append({
                '–ú–µ—Ç—Ä–∏–∫–∞': name,
                'T-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞': t_stat,
                'P-value': p_val,
                '–ó–Ω–∞—á–∏–º–æ': p_val < 0.05
            })

    results_df = pd.DataFrame(results)
    print(results_df.to_string(index=False))

    return z_score, p_value, diff, ci_lower, ci_upper


def segment_analysis(df):
    """–ê–Ω–∞–ª–∏–∑ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º"""

    print("\n" + "=" * 80)
    print("–ê–ù–ê–õ–ò–ó –ü–û –°–ï–ì–ú–ï–ù–¢–ê–ú")
    print("=" * 80)

    segments = ['device_type', 'browser', 'traffic_source']

    for segment in segments:
        print(f"\n–ê–Ω–∞–ª–∏–∑ –ø–æ —Å–µ–≥–º–µ–Ω—Ç—É: {segment}")

        segment_results = []
        for value in df[segment].unique():
            if pd.isna(value):
                continue

            segment_data = df[df[segment] == value]
            if len(segment_data) < 20:
                continue

            control_seg = segment_data[segment_data['group_name'] == 'control']
            variant_seg = segment_data[segment_data['group_name'] == 'variant']

            if len(control_seg) < 10 or len(variant_seg) < 10:
                continue

            conv_control = control_seg['converted'].mean() * 100
            conv_variant = variant_seg['converted'].mean() * 100
            diff = conv_variant - conv_control
            rel_change = (conv_variant / conv_control - 1) * 100 if conv_control > 0 else 0

            segment_results.append({
                '–°–µ–≥–º–µ–Ω—Ç': value,
                'Control (%)': f"{conv_control:.2f}",
                'Variant (%)': f"{conv_variant:.2f}",
                '–†–∞–∑–Ω–∏—Ü–∞ (%)': f"{diff:.2f}",
                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ (%)': f"{rel_change:.1f}%",
                '–†–∞–∑–º–µ—Ä Control': len(control_seg),
                '–†–∞–∑–º–µ—Ä Variant': len(variant_seg)
            })

        if segment_results:
            results_df = pd.DataFrame(segment_results)
            results_df = results_df.sort_values('–†–∞–∑–Ω–∏—Ü–∞ (%)', key=lambda x: pd.to_numeric(x.str.replace('%', '')),
                                                ascending=False)
            print(results_df.to_string(index=False))


def visualize_results(control, variant, diff, ci_lower, ci_upper):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""

    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    fig.suptitle('A/B Test Analysis Results', fontsize=16, fontweight='bold')

    # 1. –ö–æ–Ω–≤–µ—Ä—Å–∏—è –ø–æ –≥—Ä—É–ø–ø–∞–º
    ax1 = axes[0, 0]
    conv_data = pd.DataFrame({
        'Group': ['Control', 'Variant'],
        'Conversion Rate (%)': [
            control['converted'].mean() * 100,
            variant['converted'].mean() * 100
        ]
    })
    bars = ax1.bar(conv_data['Group'], conv_data['Conversion Rate (%)'],
                   color=['#3498db', '#2ecc71'])
    ax1.set_ylabel('Conversion Rate (%)')
    ax1.set_title('Conversion Rate by Group')
    ax1.grid(True, alpha=0.3)

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
    for bar in bars:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width() / 2., height + 0.1,
                 f'{height:.2f}%', ha='center', va='bottom')

    # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω–≤–µ—Ä—Å–∏–π
    ax2 = axes[0, 1]
    conversion_data = pd.DataFrame({
        'Converted': np.concatenate([
            control['converted'].values,
            variant['converted'].values
        ]),
        'Group': ['Control'] * len(control) + ['Variant'] * len(variant)
    })

    # –°–æ–∑–¥–∞–µ–º countplot –≤—Ä—É—á–Ω—É—é –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è
    control_counts = conversion_data[conversion_data['Group'] == 'Control']['Converted'].value_counts()
    variant_counts = conversion_data[conversion_data['Group'] == 'Variant']['Converted'].value_counts()

    x = np.arange(2)
    width = 0.35

    ax2.bar(x - width / 2, [control_counts.get(0, 0), control_counts.get(1, 0)],
            width, label='Control', color='#3498db')
    ax2.bar(x + width / 2, [variant_counts.get(0, 0), variant_counts.get(1, 0)],
            width, label='Variant', color='#2ecc71')

    ax2.set_xlabel('Converted')
    ax2.set_ylabel('Count')
    ax2.set_title('Conversion Distribution')
    ax2.set_xticks(x)
    ax2.set_xticklabels(['No', 'Yes'])
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # 3. –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª —Ä–∞–∑–Ω–∏—Ü—ã
    ax3 = axes[0, 2]
    ax3.errorbar(0, diff * 100, yerr=[(diff - ci_lower) * 100, (ci_upper - diff) * 100],
                 fmt='o', capsize=5, color='#e74c3c', markersize=8)
    ax3.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
    ax3.set_xlim(-0.5, 0.5)
    ax3.set_xticks([])
    ax3.set_ylabel('Difference in Conversion Rate (%)')
    ax3.set_title('95% Confidence Interval for Difference')
    ax3.grid(True, alpha=0.3)

    # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é
    ax3.annotate(f'Diff: {diff * 100:.2f}%\nCI: [{ci_lower * 100:.2f}%, {ci_upper * 100:.2f}%]',
                 xy=(0, diff * 100), xytext=(0.2, diff * 100 + 0.2),
                 arrowprops=dict(arrowstyle='->', color='black'))

    # 4. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ —á–µ–∫–∞
    ax4 = axes[1, 0]
    order_data = pd.DataFrame({
        'Order Amount': np.concatenate([
            control['order_amount'].dropna().values,
            variant['order_amount'].dropna().values
        ]),
        'Group': ['Control'] * len(control['order_amount'].dropna()) +
                 ['Variant'] * len(variant['order_amount'].dropna())
    })

    order_data.boxplot(column='Order Amount', by='Group', ax=ax4, grid=True)
    ax4.set_title('Order Amount Distribution')
    ax4.set_ylabel('Order Amount ($)')
    ax4.set_xlabel('')

    # 5. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π
    ax5 = axes[1, 1]
    events_data = pd.DataFrame({
        'Total Events': np.concatenate([
            control['total_events'].values,
            variant['total_events'].values
        ]),
        'Group': ['Control'] * len(control) + ['Variant'] * len(variant)
    })

    events_data.boxplot(column='Total Events', by='Group', ax=ax5, grid=True)
    ax5.set_title('Total Events Distribution')
    ax5.set_ylabel('Number of Events')
    ax5.set_xlabel('')

    # 6. –ö–æ–Ω–≤–µ—Ä—Å–∏—è –ø–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º
    ax6 = axes[1, 2]
    device_data = pd.concat([control, variant])
    device_conv = device_data.groupby(['device_type', 'group_name'])['converted'].mean().unstack() * 100

    device_conv.plot(kind='bar', ax=ax6, color=['#3498db', '#2ecc71'])
    ax6.set_title('Conversion Rate by Device Type')
    ax6.set_ylabel('Conversion Rate (%)')
    ax6.set_xlabel('Device Type')
    ax6.legend(title='Group')
    ax6.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('ab_test_results.png', dpi=300, bbox_inches='tight')
    plt.show()

    print(f"\n–ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: ab_test_results.png")


def calculate_sample_size():
    """–†–∞—Å—á–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏"""

    print("\n" + "=" * 80)
    print("–†–ê–°–ß–ï–¢ –ù–ï–û–ë–•–û–î–ò–ú–û–ì–û –†–ê–ó–ú–ï–†–ê –í–´–ë–û–†–ö–ò")
    print("=" * 80)

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞
    baseline_rate = 0.08  # 8% –∫–æ–Ω–≤–µ—Ä—Å–∏—è –≤ –∫–æ–Ω—Ç—Ä–æ–ª–µ
    mde = 0.15  # Minimum Detectable Effect (15%)
    alpha = 0.05  # –£—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
    power = 0.8  # –ú–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞

    effect_size = proportion.proportion_effectsize(
        baseline_rate,
        baseline_rate * (1 + mde)
    )

    power_analysis = power.NormalIndPower()
    required_n = power_analysis.solve_power(
        effect_size=effect_size,
        power=power,
        alpha=alpha,
        ratio=1  # —Ä–∞–≤–Ω—ã–µ –≥—Ä—É–ø–ø—ã
    )

    print(f"–ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –∫–æ–Ω–≤–µ—Ä—Å–∏–∏: {baseline_rate * 100:.1f}%")
    print(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç (MDE): {mde * 100:.0f}%")
    print(f"–£—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ (alpha): {alpha}")
    print(f"–ú–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞ (power): {power}")
    print(f"–≠—Ñ—Ñ–µ–∫—Ç –ö–æ—ç–Ω–∞ (h): {effect_size:.3f}")
    print(f"\n–¢—Ä–µ–±—É–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –ù–ê –ì–†–£–ü–ü–£: {required_n:.0f} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
    print(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏: {required_n * 2:.0f} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –±—ã–ª–æ –¥–∞–Ω–Ω—ã—Ö –≤ –Ω–∞—à–µ–º —Ç–µ—Å—Ç–µ
    actual_power = power_analysis.solve_power(
        effect_size=effect_size,
        nobs1=5000,  # –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º —Ä–∞–∑–º–µ—Ä –≥—Ä—É–ø–ø—ã
        alpha=alpha,
        ratio=1
    )

    print(f"\n–ü—Ä–∏ —Ä–∞–∑–º–µ—Ä–µ –≥—Ä—É–ø–ø—ã 5000 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π:")
    print(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞—è –º–æ—â–Ω–æ—Å—Ç—å: {actual_power:.3f}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""

    print("A/B TEST STATISTICAL ANALYSIS")
    print("=" * 80)

    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        engine = connect_to_db()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        df = load_ab_test_data(engine)
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")

        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        control, variant = calculate_basic_metrics(df)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
        z_score, p_value, diff, ci_lower, ci_upper = perform_statistical_tests(control, variant)

        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º
        segment_analysis(df)

        # –†–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏
        calculate_sample_size()

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        visualize_results(control, variant, diff, ci_lower, ci_upper)

        # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
        print("\n" + "=" * 80)
        print("–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
        print("=" * 80)

        if p_value < 0.05:
            print("‚úÖ –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò –ó–ù–ê–ß–ò–ú–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢")
            print(f"   –ù–æ–≤–∞—è –≤–µ—Ä—Å–∏—è (variant) –ø–æ–∫–∞–∑–∞–ª–∞ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏ –Ω–∞ {diff * 100:.2f}%")
            print(
                f"   –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: {(variant['converted'].mean() / control['converted'].mean() - 1) * 100:.1f}%")

            if diff > 0:
                print("\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –í–Ω–µ–¥—Ä–∏—Ç—å –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é")
            else:
                print("\n‚ö†Ô∏è  –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –û—Å—Ç–∞–≤–∏—Ç—å —Ç–µ–∫—É—â—É—é –≤–µ—Ä—Å–∏—é")
        else:
            print("‚ùå –ù–ï–¢ –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–û–ô –ó–ù–ê–ß–ò–ú–û–°–¢–ò")
            print("   –†–∞–∑–Ω–∏—Ü–∞ –≤ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ–π")
            print("\nüîç –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø:")
            print("   1. –£–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏")
            print("   2. –ü—Ä–æ–¥–ª–∏—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞")
            print("   3. –ü—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º –¥–ª—è –ø–æ–∏—Å–∫–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–æ–≤")

        # –ë–∏–∑–Ω–µ—Å-–æ—Ü–µ–Ω–∫–∞
        print("\n" + "=" * 80)
        print("–ë–ò–ó–ù–ï–°-–û–¶–ï–ù–ö–ê –≠–§–§–ï–ö–¢–ê")
        print("=" * 80)

        monthly_users = 100000  # –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º
        avg_order_value = variant['order_amount'].mean()

        if not np.isnan(avg_order_value) and diff > 0:
            additional_conversions = monthly_users * diff
            additional_revenue = additional_conversions * avg_order_value

            print(f"–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π –º–µ—Å—è—á–Ω—ã–π —Ç—Ä–∞—Ñ–∏–∫: {monthly_users:,} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
            print(f"–°—Ä–µ–¥–Ω–∏–π —á–µ–∫: ${avg_order_value:.2f}")
            print(f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏ –≤ –º–µ—Å—è—Ü: {additional_conversions:.0f}")
            print(f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤—ã—Ä—É—á–∫–∞ –≤ –º–µ—Å—è—Ü: ${additional_revenue:,.2f}")
            print(f"–ì–æ–¥–æ–≤–∞—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤—ã—Ä—É—á–∫–∞: ${additional_revenue * 12:,.2f}")

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()